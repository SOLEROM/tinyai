{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d8acd1-4a2b-40f9-a059-e3fd57f79bb5",
   "metadata": {},
   "source": [
    "## NLP play "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77bb65-1a65-414b-86ad-18cdba5da999",
   "metadata": {},
   "source": [
    "This model is using the \"IMDb Large Movie Review dataset\" from the paper \"Learning Word Vectors for Sentiment Analysis\" by Andrew Maas et al. It works well with movie reviews of many thousands of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5face36-90f1-4714-8f1f-7e029fd02492",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name dataclass_transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mTextDataLoaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43muntar_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mURLs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMDB\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m learn \u001b[38;5;241m=\u001b[39m text_classifier_learner(dls, AWD_LSTM, drop_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, metrics\u001b[38;5;241m=\u001b[39maccuracy)\n\u001b[1;32m      7\u001b[0m learn\u001b[38;5;241m.\u001b[39mfine_tune(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/text/data.py:255\u001b[0m, in \u001b[0;36mTextDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, text_vocab, is_lm, tok_tfm, seq_len, splitter, backwards, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m splitter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m GrandparentSplitter(train_name\u001b[38;5;241m=\u001b[39mtrain, valid_name\u001b[38;5;241m=\u001b[39mvalid) \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m RandomSplitter(valid_pct, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m--> 255\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\u001b[43mTextBlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackwards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtok_tfm\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_lm: blocks\u001b[38;5;241m.\u001b[39mappend(CategoryBlock(vocab\u001b[38;5;241m=\u001b[39mvocab))\n\u001b[1;32m    257\u001b[0m get_items \u001b[38;5;241m=\u001b[39m partial(get_text_files, folders\u001b[38;5;241m=\u001b[39m[train,valid]) \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m get_text_files\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/text/data.py:242\u001b[0m, in \u001b[0;36mTextBlock.from_folder\u001b[0;34m(cls, path, vocab, is_lm, seq_len, backwards, min_freq, max_vocab, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;129m@delegates\u001b[39m(Tokenizer\u001b[38;5;241m.\u001b[39mfrom_folder, keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_folder\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path, vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, is_lm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m72\u001b[39m, backwards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60000\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild a `TextBlock` from a `path`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, vocab\u001b[38;5;241m=\u001b[39mvocab, is_lm\u001b[38;5;241m=\u001b[39mis_lm, seq_len\u001b[38;5;241m=\u001b[39mseq_len,\n\u001b[1;32m    243\u001b[0m                backwards\u001b[38;5;241m=\u001b[39mbackwards, min_freq\u001b[38;5;241m=\u001b[39mmin_freq, max_vocab\u001b[38;5;241m=\u001b[39mmax_vocab)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/text/core.py:280\u001b[0m, in \u001b[0;36mTokenizer.from_folder\u001b[0;34m(cls, path, tok, rules, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;129m@delegates\u001b[39m(tokenize_folder, keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_folder\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path, tok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rules\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    279\u001b[0m     path \u001b[38;5;241m=\u001b[39m Path(path)\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tok \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: tok \u001b[38;5;241m=\u001b[39m \u001b[43mWordTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m tokenize_folder(path, tok\u001b[38;5;241m=\u001b[39mtok, rules\u001b[38;5;241m=\u001b[39mrules, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    282\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(tok, counter\u001b[38;5;241m=\u001b[39mload_pickle(output_dir\u001b[38;5;241m/\u001b[39mfn_counter_pkl),\n\u001b[1;32m    283\u001b[0m               lengths\u001b[38;5;241m=\u001b[39mload_pickle(output_dir\u001b[38;5;241m/\u001b[39mfn_lengths_pkl), rules\u001b[38;5;241m=\u001b[39mrules, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfolder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/text/core.py:116\u001b[0m, in \u001b[0;36mSpacyTokenizer.__init__\u001b[0;34m(self, lang, special_toks, buf_sz)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, special_toks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, buf_sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbols\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTH\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_toks \u001b[38;5;241m=\u001b[39m ifnone(special_toks, defaults\u001b[38;5;241m.\u001b[39mtext_spec_tok)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/errors.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/compat.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/thinc/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/thinc/config.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, Promise, VARIABLE_RE\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/confection/__init__.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfigparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParsingError\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, create_model, ValidationError, Extra\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelMetaclass\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfields\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelField\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pydantic/__init__.py:2\u001b[0m, in \u001b[0;36minit pydantic.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pydantic/dataclasses.py:41\u001b[0m, in \u001b[0;36minit pydantic.dataclasses\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name dataclass_transform"
     ]
    }
   ],
   "source": [
    "from fastbook import *\n",
    "\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c15c56-1091-49c1-8345-87fa355ab867",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(\"I really liked that movie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d7273-4c47-48ad-8cad-d1da7f8e3e3c",
   "metadata": {},
   "source": [
    "see the model has considered the review to be positive. The second part of the result is the index of \"pos\" in our data vocabulary and the last part is the probabilities attributed to each class (99.6% for \"pos\" and 0.4% for \"neg\"). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
